# Papers

## Machine Learning

- [ ] [Deep Gaussian Mixture Models](https://arxiv.org/abs/1711.06929)
- [ ] [Variational Dropout Sparsifies Deep Neural Networks](https://arxiv.org/abs/1701.05369)
- [ ] [MinimalRNN: Toward More Interpretable and Trainable Recurrent Neural Networks](https://arxiv.org/abs/1711.06788)
- [ ] [A Resizable Mini-batch Gradient Descent based on a Randomized Weighted Majority](https://arxiv.org/abs/1711.06424)
- [ ] [Simple And Efficient Architecture Search for Convolutional Neural Networks](https://arxiv.org/abs/1711.04528)
- [ ] [High-dimensional dynamics of generalization error in neural networks](https://arxiv.org/abs/1710.03667)
- [ ] [Matrix capsules with EM routing](https://openreview.net/forum?id=HJWLfGWRb)
- [ ] [Data Augmentation Generative Adversarial Networks](https://arxiv.org/abs/1711.04340)
- [ ] [Variance Reduced methods for Non-convex Composition Optimization](https://arxiv.org/abs/1711.04416)
- [ ] [Simple And Efficient Architecture Search for Convolutional Neural Networks](https://arxiv.org/abs/1711.04528)
- [ ] [Learning and Real-time Classification of Hand-written Digits With Spiking Neural Networks](https://arxiv.org/abs/1711.03637)
- [ ] [The (Un)reliability of saliency methods](https://arxiv.org/abs/1711.00867)
- [ ] [Variational Walkback: Learning a Transition Operator as a Stochastic Recurrent Net](https://arxiv.org/abs/1711.02282)
- [ ] [Deep Neural Networks as Gaussian Processes](https://arxiv.org/abs/1711.00165)
- [ ] [Deep Recurrent Gaussian Process with Variational Sparse Spectrum Approximation](https://arxiv.org/abs/1711.00799)
- [ ] [Fraternal Dropout](https://arxiv.org/abs/1711.00066)
- [ ] [Don't Decay the Learning Rate, Increase the Batch Size](https://arxiv.org/abs/1711.00489)
- [ ] [Reparameterizing the Birkhoff Polytope for Variational Permutation Inference](https://arxiv.org/abs/1710.09508)
- [ ] [Variational Inference based on Robust Divergences](https://arxiv.org/abs/1710.06595)
- [ ] [Binary Classification from Positive-Confidence Data](https://arxiv.org/abs/1710.07138)
- [ ] [Kronecker Recurrent Units](https://arxiv.org/abs/1705.10142)
- [ ] [Bayesian GAN](https://arxiv.org/abs/1705.09558)
- [ ] [Learning how to explain neural networks: PatternNet and PatternAttribution](https://arxiv.org/abs/1705.05598)
- [ ] [Bayesian Recurrent Neural Networks](https://arxiv.org/abs/1704.02798)
- [ ] [Bayesian Optimization with Gradients](https://arxiv.org/abs/1703.04389)
- [ ] [Dataset Augmentation in Feature Space](https://arxiv.org/abs/1702.05538)
- [ ] [Revisiting Distributionally Robust Supervised Learning in Classification](https://arxiv.org/abs/1611.02041)
- [ ] [Make SVM great again with Siamese kernel for few-shot learning](https://openreview.net/forum?id=B1EVwkqTW)
- [ ] [Structure Discovery in Nonparametric Regression through Compositional Kernel Search](https://arxiv.org/abs/1302.4922)
- [ ] [Bayesian Hypernetworks](https://arxiv.org/abs/1710.04759)
- [ ] [Efficient Methods and Hardware for Deep Learning](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture15.pdf)
- [ ] [Seven neurons memorizing sequences of alphabetical images via spike-timing dependent plasticity](https://www.nature.com/articles/srep14149)

## Learning

- [ ] [Understanding Deep Learning Generalization by Maximum Entropy](https://arxiv.org/abs/1711.07758)
- [ ] [Deep Bayesian Active Learning with Image Data](https://arxiv.org/abs/1703.02910)
- [ ] [Aggregated Wasserstein Metric and State Registration for Hidden Markov Models](https://arxiv.org/abs/1711.05792)
- [ ] [Opening the Black Box of Deep Neural Networks via Information](https://arxiv.org/abs/1703.00810)
- [ ] [Neural Network Gradient Hamiltonian Monte Carlo](https://arxiv.org/abs/1711.05307)
- [ ] [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)
- [ ] [Unsupervised Deep Embedding for Clustering Analysis](https://arxiv.org/abs/1511.06335)
- [ ] [Unsupervised Learning by Predicting Noise](https://arxiv.org/abs/1704.05310)
- [ ] [Preparing for the Unknown: Learning a Universal Policy with Online System Identification](https://arxiv.org/abs/1702.02453)
- [ ] [Deep Hyperspherical Learning](https://arxiv.org/abs/1711.03189)
- [ ] [Backpropagation through the Void: Optimizing control variates for black-box gradient estimation](https://arxiv.org/abs/1711.00123)
- [ ] [Metric Learning-based Generative Adversarial Network](https://arxiv.org/abs/1711.02792)
- [ ] [Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks](https://arxiv.org/abs/1710.11029)
- [ ] [Information-theoretic analysis of generalization capability of learning algorithms](https://arxiv.org/abs/1705.07809)
- [ ] [A Bayesian Perspective on Generalization and Stochastic Gradient Descent](https://arxiv.org/abs/1710.06451)
- [ ] [Training Neural Networks Without Gradients: A Scalable ADMM Approach](https://arxiv.org/abs/1605.02026)
- [ ] [Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937)
- [ ] [Bayesian Uncertainty Estimation for Batch Normalized Deep Networks](https://openreview.net/forum?id=BJlrSmbAZ&noteId=BJlrSmbAZ)
- [ ] [The Implicit Bias of Gradient Descent on Separable Data](https://arxiv.org/abs/1710.10345)
- [ ] [Adaptive Sampling Strategies for Stochastic Optimization](https://arxiv.org/abs/1710.11258)
- [ ] [Learning One-hidden-layer Neural Networks with Landscape Design](https://arxiv.org/abs/1711.00501)
- [ ] [Attacking Binarized Neural Networks](https://arxiv.org/abs/1711.00449)
- [ ] [Training GANs with Optimism](https://arxiv.org/abs/1711.00141)
- [ ] [The Riemannian Geometry of Deep Generative Models](https://arxiv.org/abs/1711.08014)
- [ ] [Normalized Direction-preserving Adam](https://arxiv.org/abs/1709.04546)
- [ ] [Deep Gaussian Covariance Network](https://arxiv.org/abs/1710.06202)
- [ ] [mixup: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412)
- [ ] [Learned Optimizers that Scale and Generalize](https://arxiv.org/abs/1703.04813)
- [ ] [Improving training of deep neural networks via Singular Value Bounding](https://arxiv.org/abs/1611.06013)
- [ ] [Supervised Classification: Quite a Brief Overview](https://arxiv.org/abs/1710.09230)
- [ ] [Distributed Second-Order Optimization using Kronecker-Factored Approximations](https://openreview.net/forum?id=SkkTMpjex)
- [ ] [First-order Methods Almost Always Avoid Saddle Points](https://arxiv.org/abs/1710.07406)
- [ ] [A Bayesian Perspective on Generalization and Stochastic Gradient Descent](https://arxiv.org/abs/1710.06451)
- [ ] [Generalization in Deep Learning](https://arxiv.org/abs/1710.05468)
- [ ] [Training Feedforward Neural Networks with Standard Logistic Activations is Feasible](https://arxiv.org/abs/1710.01013)
- [ ] [Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks](https://arxiv.org/abs/1701.04722)
- [ ] [Energy-Based Unsupervised Learning](https://cilvr.cs.nyu.edu/lib/exe/fetch.php?media=deeplearning:dl-ebm-unsupervised.pdf)
- [ ] [Deep Variational Information Bottleneck](https://arxiv.org/abs/1612.00410)
- [ ] [Learning Deep Architectures via Generalized Whitened Neural Networks](http://personal.ie.cuhk.edu.hk/~pluo/pdf/pluoICML2017.pdf)
- [ ] [First Efficient Convergence for Streaming k-PCA: a Global, Gap-Free, and Near-Optimal Rate](https://arxiv.org/abs/1607.07837)
- [ ] [Learning Scalable Deep Kernels with Recurrent Structure](https://arxiv.org/abs/1610.08936)
- [ ] [On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima](https://arxiv.org/abs/1609.04836)
- [ ] [Optimizing Neural Networks with Kronecker-factored Approximate Curvature](https://arxiv.org/abs/1503.05671)
- [ ] [A Tutorial on Energy-Based Learning](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf)

## Natural Language Processing

- [ ] [Detecting and Explaining Crisis](https://arxiv.org/abs/1705.09585)
- [ ] [Breaking the Softmax Bottleneck: A High-Rank RNN Language Model](https://arxiv.org/abs/1711.03953)
- [ ] [Improving Distributional Similarity with Lessons Learned from Word Embeddings](http://www.aclweb.org/anthology/Q15-1016)
- [ ] [Language as a Latent Variable: Discrete Generative Models for Sentence Compression](https://arxiv.org/abs/1609.07317)
- [ ] [Compressing Word Embeddings via Deep Compositional Code Learning](https://arxiv.org/abs/1711.01068)
- [ ] [Improving Negative Sampling for Word Representation using Self-embedded Features](https://arxiv.org/abs/1710.09805)
- [ ] [Unsupervised Neural Machine Translation](https://arxiv.org/abs/1710.11041)
- [ ] [Unsupervised Machine Translation Using Monolingual Corpora Only](https://arxiv.org/abs/1711.00043)
- [ ] [Using k-way Co-occurrences for Learning Word Embeddings](https://arxiv.org/abs/1709.01199)
- [ ] [Paraphrase Generation with Deep Reinforcement Learning](https://arxiv.org/abs/1711.00279)
- [ ] [One-shot and few-shot learning of word embeddings](https://arxiv.org/abs/1710.10280)
- [ ] [Understanding Neural Networks through Representation Erasure](https://arxiv.org/abs/1612.08220)
- [ ] [Baselines and Bigrams: Simple, Good Sentiment and Topic Classification](https://www.aclweb.org/anthology/P12-2018)
- [ ] [Generating Natural Adversarial Examples](https://arxiv.org/abs/1710.11342)
- [ ] [Deconvolutional Paragraph Representation Learning](https://arxiv.org/abs/1708.04729)
- [ ] [Entity Embeddings with Conceptual Subspaces as a Basis for Plausible Reasoning](https://arxiv.org/abs/1602.05765)
- [ ] [日本語単語ベクトルの構築とその評価](https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=141870&item_no=1&page_id=13&block_id=8)
- [ ] [Word Translation Without Parallel Data](https://arxiv.org/abs/1710.04087)
- [ ] [Learning the Dimensionality of Word Embeddings](https://arxiv.org/abs/1511.05392)
- [ ] [Using matrices to model symbolic relationship](https://papers.nips.cc/paper/3482-using-matrices-to-model-symbolic-relationship)

## Reinforcement Learning

- [ ] [Implementing the Deep Q-Network](https://arxiv.org/abs/1711.07478)
- [ ] [A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning](https://arxiv.org/abs/1711.00832)
- [ ] [Rainbow: Combining Improvements in Deep Reinforcement Learning](https://arxiv.org/abs/1710.02298)
- [ ] [TreeQN and ATreeC: Differentiable Tree Planning for Deep Reinforcement Learning](https://arxiv.org/abs/1710.11417)
- [ ] [Distributed Prioritized Experience Replay](https://openreview.net/forum?id=H1Dy---0Z)
- [ ] [Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations](https://arxiv.org/abs/1709.10087)
- [ ] [Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation](https://arxiv.org/abs/1708.05144)
- [ ] [Safe Model-based Reinforcement Learning with Stability Guarantees](https://arxiv.org/abs/1705.08551)

## Computer Vision

- [ ] [Representation Learning by Learning to Count](https://arxiv.org/abs/1708.06734)
- [ ] [Unsupervised learning of object frames by dense equivariant image labelling](https://arxiv.org/abs/1706.02932)
- [ ] [DiracNets: Training Very Deep Neural Networks Without Skip-Connections](https://arxiv.org/abs/1706.00388v1)
- [ ] [Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations](https://arxiv.org/abs/1710.10121)
- [ ] [Genetic CNN](https://arxiv.org/abs/1703.01513)
- [ ] [Semi and Weakly Supervised Semantic Segmentation Using Generative Adversarial Network](https://arxiv.org/abs/1703.09695)
- [ ] [Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829)
- [ ] [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196)
- [ ] [One pixel attack for fooling deep neural networks](https://arxiv.org/abs/1710.08864)
- [ ] [Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step](https://arxiv.org/abs/1710.08446)
- [ ] [Unsupervised Cross-Domain Image Generation](https://arxiv.org/abs/1611.02200)
- [ ] [StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/abs/1710.10916)
- [ ] [Learning Wasserstein Embeddings](https://arxiv.org/abs/1710.07457)
- [ ] [Do Convolutional Neural Networks Learn Class Hierarchy?](https://arxiv.org/abs/1710.06501)
- [ ] [Residual Connections Encourage Iterative Inference](https://arxiv.org/abs/1710.04773)
- [ ] [ステレオ立体視のために両眼の間で比較される脳内情報は何か？](http://www.fbs.osaka-u.ac.jp/jpn/events/achievement/kato-ohzawa-20160607/)
- [ ] [A Kronecker-factored approximate Fisher matrix for convolution layers](https://arxiv.org/abs/1602.01407)
- [ ] [One Millisecond Face Alignment with an Ensemble of Regression Trees](https://pdfs.semanticscholar.org/d78b/6a5b0dcaa81b1faea5fb0000045a62513567.pdf)
- [ ] [The Numerics of GANs](https://arxiv.org/abs/1705.10461)
- [ ] [Neural Color Transfer between Images](https://arxiv.org/abs/1710.00756)
- [ ] [Casual 3D Photography](http://visual.cs.ucl.ac.uk/pubs/casual3d/)

## Bayes

- [ ] [The Mondrian Process](http://danroy.org/papers/RoyTeh-NIPS-2009.pdf)
- [ ] [Bayesian Policy Search with Policy Priors](https://web.stanford.edu/~ngoodman/papers/WingateEtAl-PolicyPrios.pdf)
- [ ] [Variational MCMC](https://arxiv.org/abs/1301.2266)
- [ ] [Shared Segmentation of Natural Scenes Using Dependent Pitman-Yor Processes](https://papers.nips.cc/paper/3435-shared-segmentation-of-natural-scenes-using-dependent-pitman-yor-processes)
- [ ] [Pitman-Yor Diffusion Trees](https://arxiv.org/abs/1106.2494)
- [ ] [Stochastic Memoizer for Sequence Data](https://www.stats.ox.ac.uk/~teh/research/compling/WooArcGas2009a.pdf)

## Speech Synthesis 

- [ ] [Parallel WaveNet: Fast High-Fidelity Speech Synthesis](https://deepmind.com/documents/131/Distilling_WaveNet.pdf)
- [ ] [High-fidelity speech synthesis with WaveNet](https://deepmind.com/blog/high-fidelity-speech-synthesis-wavenet/)
- [ ] [Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention](https://arxiv.org/abs/1710.08969)
- [ ] [Deep Voice 3: 2000-Speaker Neural Text-to-Speech](https://arxiv.org/abs/1710.07654)
- [ ] [Tacotron: Towards End-to-End Speech Synthesis](https://arxiv.org/abs/1703.10135)

## Speech Recognition

- [ ] [Exploring Speech Enhancement with Generative Adversarial Networks for Robust Speech Recognition](https://arxiv.org/abs/1711.05747)
- [ ] [Robust Speech Recognition Using Generative Adversarial Networks](https://arxiv.org/abs/1711.01567)
- [ ] [Improving speech recognition by revising gated recurrent units](https://arxiv.org/abs/1710.00641)
- [ ] [Acoustic Modeling for Google Home](http://www.cs.cmu.edu/~chanwook/MyPapers/b_li_interspeech_2017.pdf)

## Sound

- [ ] [Singing Voice Separation with Deep U-Net Convolutional Networks](https://ismir2017.smcnus.org/wp-content/uploads/2017/10/171_Paper.pdf)
- [ ] [A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement](https://arxiv.org/abs/1709.08243)
- [ ] [Adversarial Semi-Supervised Audio Source Separation applied to Singing Voice Extraction](https://arxiv.org/abs/1711.00048)

## Information Theory

- [ ] [Ternary Residual Networks](https://arxiv.org/abs/1707.04679)
- [ ] [Fast Information-theoretic Bayesian Optimisation](https://arxiv.org/abs/1711.00673)
- [ ] [An Information-Theoretic Analysis of Deep Latent-Variable Models](https://arxiv.org/abs/1711.00464)
- [ ] [An Information Theoretic Perspective on Multiple Classifier Systems](https://pdfs.semanticscholar.org/1ff2/239cdebdf97ccfac2d2759355ed9c6f52888.pdf)
- [ ] [Information Geometry Connecting Wasserstein Distance and Kullback-Leibler Divergence via the Entropy-Relaxed Transportation Problem](https://arxiv.org/abs/1709.10219)

## Computer Graphics

- [ ] [Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting Neural Networks](https://arxiv.org/abs/1709.05418)
- [ ] [Interactive Wood Combustion for Botanical Tree Models](http://web340.server8.webgo24.de/pirk_info/papers/Pirk.etal-2017-WoodCombustion.pdf)

## Evolutionary Computing

- [ ] [Learning Explanatory Rules from Noisy Data](https://arxiv.org/abs/1711.04574)
- [ ] [Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions](https://arxiv.org/abs/1710.10304)
- [ ] [Exact solutions to the nonlinear dynamics of learning in deep linear neural networks](https://arxiv.org/abs/1312.6120)

## Algorithms

- [ ] [In-Place Initializable Arrays](https://arxiv.org/abs/1709.08900)
- [ ] [On Tensor Train Rank Minimization: Statistical Efficiency and Scalable Algorithm](https://arxiv.org/abs/1708.00132)

## Neuroscience

- [ ] [Robust Transient Dynamics and Brain Functions](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3116137/)
- [ ] [A neural algorithm for a fundamental computing problem](https://www.biorxiv.org/content/early/2017/08/25/180471.full.pdf+html)
- [ ] [Cortical microcircuits as gated-recurrent neural networks](https://arxiv.org/abs/1711.02448)
- [ ] [Learning with three factors: modulating Hebbian plasticity with errors](https://www.ncbi.nlm.nih.gov/pubmed/28918313)
- [ ] [A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs](http://science.sciencemag.org/content/early/2017/10/25/science.aag2612)
- [ ] [Comparing Hebbian Semantic Vectors Across Language](https://kiranvodrahalli.github.io/projects/neu330paper.pdf)
- [ ] [The hippocampus as a predictive map](https://www.nature.com/articles/nn.4650)

## Artificial Intelligence

- [ ] [Building Machines that Learn and Think for Themselves](https://arxiv.org/abs/1711.08378)
- [ ] [Building Machines That Learn and Think Like People](https://arxiv.org/abs/1604.00289)

## Blog

- [ ] [A Gentle Introduction to Calculating the BLEU Score for Text in Python](https://machinelearningmastery.com/calculate-bleu-score-for-text-python/)
- [ ] [Understanding the Mixture of Softmaxes (MoS)](http://smerity.com/articles/2017/mixture_of_softmaxes.html)
- [ ] [An On-device Deep Neural Network for Face Detection](https://machinelearning.apple.com/2017/11/16/face-detection.html)
- [ ] [Why Deep Learning and NLP Don't Get Along Well?](https://www.linkedin.com/pulse/why-deep-learning-nlp-dont-get-along-well-riza-c-berkan-ph-d/)
- [ ] [Using Machine Learning to predict parking difficulty](https://research.googleblog.com/2017/02/using-machine-learning-to-predict.html)
- [ ] [Using machine learning for insurance pricing optimization](https://cloud.google.com/blog/big-data/2017/03/using-machine-learning-for-insurance-pricing-optimization)
- [ ] [Statistical Machine Learning: Spring 2017](http://www.stat.cmu.edu/~ryantibs/statml/?utm_content=bufferd7867&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)
- [ ] [How to unit test machine learning code.](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765)
- [ ] [Optimizing deeper networks with KFAC in PyTorch.](https://medium.com/@yaroslavvb/optimizing-deeper-networks-with-kfac-in-pytorch-4004adcba1b0)
- [ ] [How Adversarial Attacks Work](https://blog.xix.ai/how-adversarial-attacks-work-87495b81da2d)
- [ ] [Deep learning and Backprop in the Brain (CCN 2017)](https://www.youtube.com/watch?v=W86H4DpFnLY)
